{"meta":{"title":"密斯特马的技术笔记","subtitle":"重拾初心 砥砺前行","description":null,"author":"manoo","url":"https://mayu1991.github.io","root":"/"},"pages":[{"title":"关于我","date":"2019-03-19T07:17:42.000Z","updated":"2019-03-19T07:17:51.674Z","comments":true,"path":"about/index.html","permalink":"https://mayu1991.github.io/about/index.html","excerpt":"","text":""},{"title":"文章目录","date":"2019-03-19T07:15:30.000Z","updated":"2019-03-19T08:03:07.000Z","comments":true,"path":"categories/index.html","permalink":"https://mayu1991.github.io/categories/index.html","excerpt":"","text":""},{"title":"文章标签","date":"2019-03-19T07:16:27.000Z","updated":"2019-03-19T08:03:09.696Z","comments":true,"path":"tags/index.html","permalink":"https://mayu1991.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"数据库连接池思考","slug":"数据库/数据库连接池思考","date":"2019-12-16T16:00:00.000Z","updated":"2019-12-18T09:00:02.920Z","comments":true,"path":"2019/12/17/数据库/数据库连接池思考/","link":"","permalink":"https://mayu1991.github.io/2019/12/17/数据库/数据库连接池思考/","excerpt":"","text":"为什么要聊连接池最近系统在大促期间出现了两例问题，竟然都是和数据库连接池有关。所以在这里，重点梳理下连接池和数据库的情况，并且分析下大规模集群下数据库连接会遇到的问题，以及对应的解决方案。 SQL的生命周期连接池其实是一个资源池。我们先来看下如果要执行一个sql，应用服务器和数据库的交互过程。 首先需要建立应用服务器和数据库的连接状态，即建立连接 数据库分配线程执行 进行sql解析并生成执行计划 读取必要的数据到内存中执行 通过之前创建的连接发送结果集给到客户端 关闭连接并释放资源 为什么使用连接池为什么使用长连接当客户端需要和数据库建立连接的时候，有短连接和长连接两种选择： 短连接：只在程序和数据库通信的时候建立连接，执行操作后，连接关闭。 长连接：程序之间的连接在建立之后，就一直打开，被后续程序复用。 短连接的优点是简单，占用内存资源较小。缺点是在流量大的场景下可能产生性能问题。 长连接的优点是可复用，缺点是，维持连接需要占用内存，可能导致内存浪费。 对数据库来说，创建和销毁连接涉及到CPU的运算、资源的争用、内存的分配和socket的建立等。频繁的创建连接和销毁连接，对数据库来说是不可接受的，所以长连接显然比短连接更适合数据库。 为什么使用连接池既然长连接更适合数据库，那么这时就出现了连接池。有了连接池，可以通过参数来配置连接数、连接检测、连接的生命周期等。可以做到连接的复用，减少平均连接时间，降级数据服务器的负载。 连接池的基本实现连接池其实是资源池的一种实现。类比java中的线程池，其实连接池将资源由线程换成了连接而已。 我们可以先看下线程池的处理逻辑： 连接池也是类似的处理逻辑： 线程池预热 通常情况下，连接池在启动的时候会根据最小连接数初始化连接。这一步是为了预热，保证连接池中有可用的线程，再请求大的时候，也可以根据最大连接池动态调整。 获取连接 发现有空闲的管道，可以直接使用。 如果管道都在忙： 管道的数量还没有达到最大连接数，那么直接创建一个新连接。 管道的数量达到最大连接数，进入等待队列中。 等待时间内，如果有空闲管道，可以拿到连接。 等待时间内，如果一直没有空闲管道，抛出获取连接失败的异常。 连接池监控 无非就是对连接池使用状态的监控，比如一个连接如果空闲下来了，多久没有使用需要被关闭，比如哪些错误情况下需要重新创建一下连接再放入池子，比如如何定时来验证连接是否有效等等。 连接池参数配置 最小连接数 最大连接数 等待时间 连接空闲时间 如果最小连接池设置过小，在应用业务量突增的时候（或者应用扩容），可能短时间产生连接风暴，这对数据库是不小的冲击。 如果最小连接池设置过大，就会出现连接过剩的情况，连接一方面因为超过空闲时间被销毁，而销毁后又发现小于最小连接数，又开始创建，进入循环。 如果最大连接池设置过小，可能会导致大量的连接请求处于等待状态。 如果最大连接池设置过大，在极端情况下，可能导致数据库的连接数被耗尽，进而导致业务受影响，甚至会形成一系列的连锁反应，乃至雪崩。 如果等待时间过长，虽然可以尽可能提高得到连接的效率，但是当应用并发很高，大大超过了连接池数量，队列就无法起到缓冲的作用，反而会阻塞应用，大量积压的线程会导致应用宕机。 如何优化我们可以想象下在什么场景，需要面对连接池优化的问题？无非这两点： 连接数太多 并发量太大 首先，我们来看下一个应用的连接数由哪些因素决定的： 应用服务器的数量 db数 连接池配置的最小连接数和最大连接数 e.g 假设一个应用，共100台服务器，连接2个db，连接池配置的最大连接数是10，那么这个应用的总连接数就是100*2*10 = 2000 围绕这三个因素，我们可以得到多连接数优化的基本思路： 拆分和降低连接池，降低单实例MySQL的连接数，比如原来一个实例上面有2个DB， 通过拆分一个实例只有1个DB， 那么在应用服务器不变的情况下， 连接数就变成1*500*6=3000。 提高DB响应时间，这样在系统同样处理能力的情况下，连接池的连接数可以大大减少。 减少应用集群规模。 提高DB响应时间 索引优化 //补充索引原理以及优化 事务优化 //补充事务优化 提高DB性能 数据拆分对数据进行分片，引入多个SQL实例，这样数据库的整体并发服务能力自然提升，同时由于服务压力被打散，整个数据库集群表现的性能也会更好。 DB服务器升级 提高数据库的并发能力我们可以发现，其实多连接数和高并发是相辅相成的，通过以上的手段减少连接数，一方面减轻了db服务器的压力，但是也有可能降低了应用服务器的并发能力。那有没有既能减少连接数又不影响高并发的优化方法呢？ 将事务和连接解绑，比如增加一层proxy 使用mysql线程池，线程和连接解绑 排查思路线上遇到连接数溢出的问题，问题的排查步骤？ 查看实例配置（几核几G、支持的最大连接数） 查看当前连接数（show processlist） 排查是什么动作占用了这些连接 分析连接被占用的原因 慢SQL（缺索引、join太多、查询数据没有分页等） 长事务 死锁 应急手段 服务端扩容 对请求进行分流，增加了服务端的并发处理能力。不过，应用服务器的增加同时会带来连接数的增加，在db连接数足够的情况下，可以执行这样的操作。 服务端限流 这是最快速也是最有效的方法。牺牲部分用户体验，以保住整个系统的稳定。 DB实例重启 重启应用可以释放当前连接数。弊端有： 当前连接中的数据丢失，执行失败 治标不治本，如果是性能问题，这么做只能解一时的渴 DB实例扩容 DB服务器升级，这也只适用于可以动态升级的云上服务器（比如阿里云服务器）一般的硬件服务器，升级配置还是挺麻烦的吧（个人猜测） DB服务集群扩容，涉及数据备份的问题，应该需要充分的测试和演练吧，需要一定的运维能力。 紧急代码优化 DB增加索引 修复造成死锁的代码问题 优化慢sql 知识点补充一篇搞懂TCP、HTTP、Socket、Socket连接池 引用 java并发编程的艺术 数据库连接池技术详解","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mayu1991.github.io/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://mayu1991.github.io/tags/数据库/"},{"name":"连接池","slug":"连接池","permalink":"https://mayu1991.github.io/tags/连接池/"}]},{"title":"","slug":"java基础/待解决问题","date":"2019-11-12T11:39:15.901Z","updated":"2019-11-12T11:44:50.836Z","comments":true,"path":"2019/11/12/java基础/待解决问题/","link":"","permalink":"https://mayu1991.github.io/2019/11/12/java基础/待解决问题/","excerpt":"","text":"面向对象的延迟绑定单例模式单例模式有哪些？单例模式的优缺点？为什么spring的bean都是单例的 代理模式装饰模式","categories":[],"tags":[]},{"title":"","slug":"dubbo/dubbo源码学习","date":"2019-11-11T08:42:14.490Z","updated":"2019-11-13T02:19:13.312Z","comments":true,"path":"2019/11/11/dubbo/dubbo源码学习/","link":"","permalink":"https://mayu1991.github.io/2019/11/11/dubbo/dubbo源码学习/","excerpt":"","text":"dubbo的拓展点机制官方博客解释 参考：DUBBO原理、应用 自适应类自适应类，dubbo的每一个拓展点都会有一个自适应类，如果我们没有提供，dubbo会帮我们动态的生成一个。 TIPS字节码生成工具动态加载","categories":[],"tags":[]},{"title":"String整理","slug":"java基础/String整理","date":"2019-11-08T08:50:00.000Z","updated":"2019-11-08T10:57:42.737Z","comments":true,"path":"2019/11/08/java基础/String整理/","link":"","permalink":"https://mayu1991.github.io/2019/11/08/java基础/String整理/","excerpt":"","text":"hashCode方法详解Java编程：String 类中 hashCode() 方法详解","categories":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/categories/知识点/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/tags/java基础/"},{"name":"String","slug":"String","permalink":"https://mayu1991.github.io/tags/String/"}]},{"title":"ArrayList整理","slug":"java基础/ArrayList整理","date":"2019-11-07T16:00:00.000Z","updated":"2019-11-08T06:49:25.391Z","comments":true,"path":"2019/11/08/java基础/ArrayList整理/","link":"","permalink":"https://mayu1991.github.io/2019/11/08/java基础/ArrayList整理/","excerpt":"","text":"ArrayList扩容处理ArrayList扩容处理","categories":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/categories/知识点/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"https://mayu1991.github.io/tags/ArrayList/"},{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/tags/java基础/"}]},{"title":"HashMap整理","slug":"java基础/HashMap整理","date":"2019-11-05T16:00:00.000Z","updated":"2019-11-08T09:45:55.468Z","comments":true,"path":"2019/11/06/java基础/HashMap整理/","link":"","permalink":"https://mayu1991.github.io/2019/11/06/java基础/HashMap整理/","excerpt":"","text":"HashMap 的工作原理及代码实现大纲 关键属性 12345transient Entry[] table;//存储元素的实体数组（桶）transient int size;//存放元素的个数int threshold; //临界值= 加载因子*容量，当实际大小超过临界值时 final float loadFactor; //加载因子，记录数/容量，默认值0.75transient int modCount;//被修改的次数，HashMap内部结构发生变化的次数 关键动作 初始化 容量，默认16 负载因子，默认0.75f hash hashcode的生成 Object对象：内存地址 String对象：char数组每一位都参与运算，对于相同值的String，hashcode是相同的 Integer：Integer的value key的hash一次扰动（高位也参与异或计算，增加hash的分散性） 散列函数 (length-1)&amp;hash 扩容 扩容后的容量 当前容量的两倍 先插入再扩容 再hash 插入 删除 查询 问题size和threshold的区别 size是map中实际存在的键值对数量 threshold是map内最大装载的元素的个数 当size达到threshold时，就会触发reSize和reHash 为什么HashMap的桶的大小为2的指数倍？我们在使用hashmap的时候，肯定是期望碰撞越小越好。 那么如何达到这个目的呢？ 我觉得可以从以下三点入手： 更大的存储空间，当然可以使数据的分布更分散 更好的的散列函数，使数据的分布更均匀 解决冲突的方法 怎么实现更大的存储空间呢？ 增加内存空间 增加负载因子 内存空间和负载因子的抉择，就是经典的「时间-空间」问题。是牺牲时间换取空间，还是牺牲空间换取时间？视实际情况而定。可以用一句话总结：「负载因子越大，碰撞的概率越大；负载因子越小，碰撞的概率变小，但是内存闲置的概率也会增加」 HashMap的初始空间和初始的负载因子分别是16和0.75f，通常不建议改变负载因子，初始空间建议按照expectSize/0.75 + 1来设置，为什么这么设计，因为扩容是一个很耗资源的操作，我们如果能预估到map中元素的个数，依照这个预估值设置容量，可以减少扩容的操作。 更好的散列函数？ 我们知道其实hash就是一个以空间换时间的设计。每一个key通过散列函数的计算，放入相应的位置上。最好的方式是根据桶的大小（hashmap的）计算取余。 桶的大小怎么设计才合理 散列函数怎么设计才合理 桶的大小有证明其实素数在打散的效果上是更好的，可以参考这个文章为什么一般的hashTable的桶数会取一个素数。但是HashMap还是选择了2的指数幂作为桶数。这就引出了「为什么HashMap的桶的大小为2的指数倍」这个问题。 散列函数为什么HashMap的桶的大小为2的指数倍？这是从性能角度出发的，为了优化用位运算代替取余运算，同时也方便在扩容时优化。 只有长度为2的指数幂的时候，位运算和取余运算才相等，这个时候散列函数计算结果比较分散。 网上有一种说法，如果length为奇数，length-1为偶数，最后一位肯定是0，这时位运算之后，最后一位永远是零，散列就不分散了。我觉得这个说法不是这个问题的原因，而是结果。 总结一下，因为选择用位运算代替除法来作为散列函数，而为了保证位运算的足够分散，选择了2的指数幂作为标准。（ps：因为选择了2的指数幂，在扩容时还可以更快捷） 为什么扩容之后的size是两倍因为hashmap的容量是2的指数幂，所以扩容之后也必须是2的指数幂，扩容的倍数当然也是2的指数幂。至于为什么是两倍，这应该是一个取舍，一下子不需要扩太多。 为什么先插入再扩容而不是先扩容再插入 hashmap的插入有可能是覆盖原有的值，这个时候size并没有增加，如果是先扩容后插入，会造成资源浪费。 因为hashmap是数组+链表，并且有负载因子，所以先插入并不会带来溢出的问题。而扩容是很耗资源的操作，能避免则避免。 rehash带来的死锁ConcurrentHashMap 的工作原理及代码实现 如何统计所有的元素个数?? 锁分段技术 获取segment 根据concurrentLevel确定segment数组的大小，其实就是确定锁的多少 获取hash，需要再散列，为了把分布打散，比hashMap打散的更彻底 getvolitile修饰所有变量，保持可见性 put （1）判断容量是否足够，如果不够的话，对segment扩容，新建一个2倍大小的数组插入，先判断后扩容，hash是先扩容后判断 （2）加锁插入，其实segment内部的实现跟hashmap很相似 size将所有的segment的大小相加，但是在多线程的时候，不能保证count的值在计算的过程中不变化，所以会尝试两次计算size，如果两次都失败了，再锁住所有segment，进行容量计算。 对比 HashMap 和 Hashtable 的区别http://www.importnew.com/24822.html（1）hashtable是线程安全的，所有的方法都加上了synchronized（2）初始容量、扩容和hash算法不同hashMap 16，扩容是*2，hash直接用位运算取模，效率高但是偶数分布不均匀，所以又跟length-1与了一下，将hash打散hashTable 11，扩容是*2+1，hash用除法取模，分布均匀但是效率比较低（3）1.8以及以后，hashmap的链表用红黑树存储了，提高了查询效率 HashMap 和 HashSet 区别https://blog.csdn.net/u010698072/article/details/52802179hashSet其实内部就是用hashMap实现的，hashSet服务于对象，在add的时候将这个对象作为map的key，set内部会new一个final类型修饰的Object作为value。 HashMap 和 ConcurrentHashMap 的区别ConcurrentHashMap是线程安全的，ConcurrentHashMap使用了锁分段技术，维护了一个继承ReetrantLock的的segment数组，每一个segment对象对应部分Entry。 java 1.7和1.8版本中hashmap的区别 常见方案 hashMap的优化方案http://www.importnew.com/21429.html 谈谈HashMap，哈希表解决hash冲突的方法； 开放定址 再hash 链地址法 建立公共溢出区参考 java 8 在链表长度达到8，桶的数量达到64的时候，会建一个红黑树来保存元素 多线程情况下HashMap死循环的问题两个线程在rehash的时候，因为有next = e.next;e = next;的操作，有可能形成环路。参考 hashMap什么时候用到红黑树java1.8中当单链的长度超过8的时候会转化为红黑树什么是红黑树https://blog.csdn.net/sun_tttt/article/details/65445754 HashMap出现Hash DOS攻击的问题把key都设计成一个hash，这样插入就成为一个单链表结构了https://coolshell.cn/articles/6424.html 一致性hash算法 参考 TIPSHashMap的求余%和与运算&amp;转换问题HashMap原理和源码分析HashTable的桶数为什么取素数HashMap的结构，1.7和1.8有哪些区别HashMap的扩容机制HashMap源码解析HashMap的hash方法剖析","categories":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/categories/知识点/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/tags/java基础/"},{"name":"hashmap","slug":"hashmap","permalink":"https://mayu1991.github.io/tags/hashmap/"},{"name":"concurrentHashMap","slug":"concurrentHashMap","permalink":"https://mayu1991.github.io/tags/concurrentHashMap/"}]},{"title":"分布式编程知识点汇总","slug":"分布式编程与锁/分布式编程与锁","date":"2019-11-03T16:00:00.000Z","updated":"2019-11-06T08:21:56.894Z","comments":true,"path":"2019/11/04/分布式编程与锁/分布式编程与锁/","link":"","permalink":"https://mayu1991.github.io/2019/11/04/分布式编程与锁/分布式编程与锁/","excerpt":"","text":"并发编程 说说 CountDownLatch、CyclicBarrier 原理和区别 CountDownLatch 允许一个线程或多个线程等待其他线程完成工作。一个获取共享状态的同步器。 CyclicBarrier 允许多个线程在都达到一个屏障的时候再放开屏障。一个锁，用锁的condition来操作，await()区别： CyclicBarrier 可以重置计数器，适合比较复杂的业务场景，提供的方法也比较多 说说 Semaphore 原理 控制同一时间并发的线程数（共享式的同步器） 在构造函数里输入并发的数量，用acquire和release来控制同步块 说说 Exchanger 原理 线程间协作，两个线程在到达同一时刻之后，可以交换数据（wait/notify）执行exchange（）方法 ThreadLocal 原理分析，ThreadLocal为什么会出现OOM，出现的深层次原理 ？？？？https://juejin.im/post/5a64a581f265da3e3b7aa02d 常见的原子操作类AtomicInteger、AtomicLong、AtomicBoolean、AtomicReference AtomicInteger底层实现原理； 一个volatile类型的value值，封装了原子性读改写的方法，利用了unsafe类的compareAndSwagObject/int/longvalue这个字段在AtomicInteger类的内存中相对于该类首地址的偏移量 Java 8并法包下常见的并发类，用过并发包下边的哪些类 AQS同步队列(ReetrantLock依赖AQS) 同步状态state控制获取锁的方式（共享、独占、可重入）。 同步队列实现，实现线程的排队、等待和唤醒的工作。 fork/join https://juejin.im/post/59be875e5188257e6b6d91c1 JMM不保证对64位的long和double型变量的写操作具有原子性https://blog.csdn.net/luoyoub/article/details/80275539 线程与线程池 一个线程连着调用start两次会出现什么情况？会抛出一个IllegalThreadStateException wait方法能不能被重写，wait能不能被中断；不能被重写，是final修饰的，不可以被中断，wait方法会抛出中断异常。 线程池的几种实现方式 讲讲线程池的实现原理 线程池的实现？四种线程池？重要参数及原理？饱和策略有哪几种？ 线程和进程的概念、并行和并发的概念线程是操作系统执行的最小单元。并行：多个cpu并发：在同一个cpu里，多个线程同事执行同一个任务 创建线程的方式及实现三种方式：（1）继承一个线程Thread，并实现run方法（2）实现一个runnable接口（3）实现一个callable接口，这个接口支持获取线程执行的返回值 进程间通信的方式https://www.cnblogs.com/LUO77/p/5816326.html 说说线程安全问题，什么是线程安全，如何保证线程安全 线程状态以及API怎么操作会发生这种转换；NEW newRUNNALBLE startBLOCKED 尝试进入synchonized区域TERMINATED 执行完run的时候WAITING wait、join、sleep（time——waiting状态，时间到了自己唤醒自己） 锁 重入锁的概念，重入锁为什么可以防止死锁支持重进入的锁，可重入锁对象在线程尝试去获取同步状态的时候，会先判断状态，如果等于0，那就是第一次进入，进行正常的锁获取，如果大于0的时候，判断当然锁是不是只属于当前线程，如果是，状态值就是获取锁的次数。 产生死锁的四个条件（互斥、请求与保持、不剥夺、循环等待） 如何检查死锁（通过jConsole检查死锁） 常用的避免死锁方法； 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用 lock.tryLock(timeout) 来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 CAS无锁的概念、乐观锁和悲观锁 利用java提供的cmpxchg指令，完成操作的同步。 对于竞争比较小的，占用资源时间比较短的业务场景，可以使用CAS的模式来代替加锁，这种方式响应时间快，但是如果一直自旋的话也会消耗大量的cpu。 如果加了锁的话，所有获取该锁的线程都要处于阻塞状态，响应时间慢，追求吞吐量。 乐观锁：cas的概念，乐观的认为出现竞争的机会比较小，通过比较原始值和最新值的方式来更新。 悲观锁：同步的概念，悲观的认为每次更新都有可能会出错，所以锁住这个资源，同一时刻只允许一个线程操作。 CAS机制会出现什么问题； 乐观锁只能保证一个共享变量的原子操作。如上例子，自旋过程中只能保证value变量的原子性，这时如果多一个或几个变量，乐观锁将变得力不从心，但互斥锁能轻易解决，不管对象数量多少及对象颗粒度大小。 长时间自旋可能导致开销大。假如CAS长时间不成功而一直自旋，会给CPU带来很大的开销。 ABA问题。CAS的核心思想是通过比对内存值与预期值是否一样而判断内存值是否被改过，但这个判断逻辑不严谨，假如内存值原来是A，后来被一条线程改为B，最后又被改成了A，则CAS认为此内存值并没有发生改变，但实际上是有被其他线程改过的，这种情况对依赖过程值的情景的运算结果影响很大。解决的思路是引入版本号，每次变量更新都把版本号加一。 什么是ABA问题，出现ABA问题JDK是如何解决的Cas带来的问题，因为cas的机制是对比历史值，在某些场景下，有可能其他线程修改完之后改成了历史值，这个时候cas也是可以成功的。在jdk里有一个atomicStampedReference类，可以在比较的时候再加上标签比较。 乐观锁的业务场景及实现方式 读取频繁用乐观锁，写入频繁用悲观锁 https://blog.csdn.net/claram/article/details/53959367 偏向锁、轻量级锁、重量级锁、自旋锁的，自适应自旋锁，锁消除，锁粗化，锁的升级 synchronized与ReentraLock哪个是公平锁；Synchronized 是非公平锁，因为它无法保证释放的锁会被哪个线程获取到。Reentrant 既有公平锁也有非公平锁 synchronized 与 lock 的区别 lock ：虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。 尝试非阻塞地获取锁 能被中断地获取锁 超时获取锁 Lock是基于同步队列实现的 synchronized 使用synchronized关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方式简化了同步的管理，可是扩展性没有显示的锁获取和释放来的好。 synchronized是jvm内部实现的","categories":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/categories/知识点/"}],"tags":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/tags/知识点/"},{"name":"分布式编程","slug":"分布式编程","permalink":"https://mayu1991.github.io/tags/分布式编程/"},{"name":"锁","slug":"锁","permalink":"https://mayu1991.github.io/tags/锁/"},{"name":"线程池","slug":"线程池","permalink":"https://mayu1991.github.io/tags/线程池/"},{"name":"并发","slug":"并发","permalink":"https://mayu1991.github.io/tags/并发/"}]},{"title":"常用关键字","slug":"java基础/常用关键字","date":"2019-09-02T16:00:00.000Z","updated":"2019-11-18T09:27:03.860Z","comments":true,"path":"2019/09/03/java基础/常用关键字/","link":"","permalink":"https://mayu1991.github.io/2019/09/03/java基础/常用关键字/","excerpt":"","text":"transientJava transient关键字使用小记 一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。 被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化。 volatile 实现原理禁止指令重排、刷新内存LoadLoad：禁止上面的volatile读与下面的普通读重排序LoadStore：禁止上面的volatile读与下面的普通写重排序StoreLoad：禁止上面的volatile写与下面的volatile读/写重排序StoreStore：禁止上面的所有操作与下面的volatile写重排序 synchronized 实现原理（对象监视器）利用了对象的对象监视器 monitor ，每一个对象都有自己的对象锁，当这个对象被synchronized修饰了之后，jvm编译的时候会在获取这个对象实例之前插入一个monitor enter指令 final关键字的内存语义参考 final可以修饰类，该类不能被继承。 final可以修饰方法，该方法不能被重写。(覆盖，复写) final可以修饰变量，该变量不能被重新赋值。因为这个变量其实是常量。 final如果修饰形参，其实仍然是可以对这个参数修改。","categories":[{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/categories/java基础/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/tags/java基础/"}]},{"title":"java基础知识点汇总","slug":"java基础/java基础整理","date":"2019-08-31T16:00:00.000Z","updated":"2019-11-06T08:41:50.354Z","comments":true,"path":"2019/09/01/java基础/java基础整理/","link":"","permalink":"https://mayu1991.github.io/2019/09/01/java基础/java基础整理/","excerpt":"","text":"序列化 序列化的使用场景与意义 https://juejin.im/post/5ce3cdc8e51d45777b1a3cdf#hserialversionuid 序列化版本号的作用 https://blog.csdn.net/yangyang3_/article/details/80718768 位移运算参考 向左位移相当于乘以 2^n ,向右移动正数相当于除以 2^n （ n 为位移的位数）比如1&lt;&lt;30，表示1乘以2^30","categories":[{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/categories/知识点/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://mayu1991.github.io/tags/java基础/"},{"name":"知识点","slug":"知识点","permalink":"https://mayu1991.github.io/tags/知识点/"}]},{"title":"常用工具记录","slug":"开发工具/常用工具记录","date":"2019-07-16T11:10:00.000Z","updated":"2019-07-16T11:16:19.085Z","comments":true,"path":"2019/07/16/开发工具/常用工具记录/","link":"","permalink":"https://mayu1991.github.io/2019/07/16/开发工具/常用工具记录/","excerpt":"","text":"JSON一个包含很多实用工具的网站简单的json格式化 时间戳转化工具http://tool.chinaz.com/Tools/unixtime.aspx 图床https://toolinbox.net/iPic/ 在线颜色选择器http://www.shouce.ren/tool/yanse 在线图片去底色工具http://www.aigei.com/bgremover 在线二维码生成器http://www.liantu.com/ pdf转wordhttps://smallpdf.com/cn/pdf-to-word","categories":[{"name":"工具","slug":"工具","permalink":"https://mayu1991.github.io/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://mayu1991.github.io/tags/工具/"}]},{"title":"spring validation 使用踩坑","slug":"java基础/spring validation 使用踩坑","date":"2019-04-09T16:00:00.000Z","updated":"2019-07-10T08:33:14.793Z","comments":true,"path":"2019/04/10/java基础/spring validation 使用踩坑/","link":"","permalink":"https://mayu1991.github.io/2019/04/10/java基础/spring validation 使用踩坑/","excerpt":"","text":"java使用validator进行校验 JSR 303 - Bean Validation 介绍及最佳实践","categories":[{"name":"spring","slug":"spring","permalink":"https://mayu1991.github.io/categories/spring/"}],"tags":[{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"spring","slug":"spring","permalink":"https://mayu1991.github.io/tags/spring/"},{"name":"validation","slug":"validation","permalink":"https://mayu1991.github.io/tags/validation/"}]},{"title":"分布式一致性协议","slug":"分布式/一致性协议/分布式一致性协议","date":"2019-04-01T16:00:00.000Z","updated":"2019-07-10T08:31:36.014Z","comments":true,"path":"2019/04/02/分布式/一致性协议/分布式一致性协议/","link":"","permalink":"https://mayu1991.github.io/2019/04/02/分布式/一致性协议/分布式一致性协议/","excerpt":"","text":"Paxos协议https://blog.csdn.net/cnh294141800/article/details/53768464 https://www.zhihu.com/question/19787937 Raft协议","categories":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"一致性协议","slug":"一致性协议","permalink":"https://mayu1991.github.io/tags/一致性协议/"}]},{"title":"自己动手写一个简单的探针（一）","slug":"链路监控/自己动手写一个简单的javaagent（一）","date":"2019-03-03T16:00:00.000Z","updated":"2019-03-19T08:08:09.151Z","comments":true,"path":"2019/03/04/链路监控/自己动手写一个简单的javaagent（一）/","link":"","permalink":"https://mayu1991.github.io/2019/03/04/链路监控/自己动手写一个简单的javaagent（一）/","excerpt":"需求 实现一个简单的javaagent。","text":"需求 实现一个简单的javaagent。 编码Step1 搭建agent的框架，实现动态加载 Premain.java 1234567public class Premain &#123; public static void premain(String agentArgs, Instrumentation inst) throws ClassNotFoundException, UnmodifiableClassException &#123; System.out.println(\"enter agent premain...\"); inst.addTransformer(new Transformer()); &#125;&#125; Transformer.java 1234567891011121314151617181920212223242526272829303132333435363738394041public class Transformer implements ClassFileTransformer &#123; private static final Set&lt;String&gt; classNameSet = new HashSet&lt;&gt;(); static &#123; classNameSet.add(\"com.example.demo.AgentTest\"); &#125; /** * 增强类 eg:静态注入监控代码 * * @param className 类名 * @return */ public byte[] enhanceMethod(String className) &#123; //增强代码 todo return new byte[0]; &#125; /** * 每加载一个类都会调用？ * * @param l * @param className * @param c * @param pd * @param b * @return * @throws IllegalClassFormatException */ public byte[] transform(ClassLoader l, String className, Class&lt;?&gt; c, ProtectionDomain pd, byte[] b) throws IllegalClassFormatException &#123; //判断当前的类是否需要转换 String currentClassName = className.replaceAll(\"/\", \".\"); if (!classNameSet.contains(currentClassName)) &#123; // 仅仅提升Set中含有的类 return null; &#125; //返回增强之后的类 return enhanceMethod(className); &#125;&#125; pom.xml 1234567891011121314151617&lt;build&gt; &lt;finalName&gt;myagent&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;com.manoo.agent.Premain&lt;/Premain-Class&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 新建了一个springboot项目，在VM options里加上以下指令测试javaagent 1-javaagent:/Users/mayu/Documents/mycodes/myagent/target/myagent.jar 123456789@SpringBootApplicationpublic class TestagentApplication &#123; public static void main(String[] args) &#123; System.out.println(\"application main\"); SpringApplication.run(TestagentApplication.class, args); &#125;&#125; 启动之后发现程序有报错 12345678Exception in thread &quot;main&quot; java.lang.ClassNotFoundException: com.manoo.agent.Premain at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:304) at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:401)FATAL ERROR in native method: processing of -javaagent failed 看了下myagent.jar包里是有这个类的，路径也没有问题。为什么会找不到这个类？ 猜测是类加载器的问题。于是研究了下javaagent的类加载原理，发现不是classloader的问题。 因为双亲类加载的原因，javaagent是无法获取应用程序的类，但是我这里是直接获取javaagent自己的类，所以不是classloader的问题。 ClassNotFoundException: 真的会使你的JVM慢下来吗？ 深入理解Java ClassLoader及在 JavaAgent 中的应用 将myagent.jar解压了一下，发现确实没有com.manoo.agent.Premain这个类，再看看发现我的classes类是在BOOT-INF/classes 路径下了。为了方便，我是直接用Spring boot创建的项目。用了spring-boot-maven-plugin打包，导致项目被打成了Spring boot的结构的jar包。 1234&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt; 后来一想如果javaagent用springboot，会不会有点太重了。目前这个javaagent功能还很简单，还不要使用框架。 于是把spring boot的依赖注释掉，重新编译了下myagent，拿到jar包之后解压了下，现在正常了。 Step2 实现被监控类的增强 判断哪些类需要被监控或者说被增强 怎么实现被监控类的增强 javassist byteBuddy（教程） 思考 代理模式 动态生成字节码的框架有哪些，效率如何？","categories":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/categories/链路监控/"}],"tags":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/tags/链路监控/"},{"name":"javaagent","slug":"javaagent","permalink":"https://mayu1991.github.io/tags/javaagent/"},{"name":"java","slug":"java","permalink":"https://mayu1991.github.io/tags/java/"}]},{"title":"自己动手写一个简单的探针(总纲)","slug":"链路监控/自己动手写一个简单的javaagent（总纲）","date":"2019-03-02T16:00:00.000Z","updated":"2019-07-10T08:28:57.814Z","comments":true,"path":"2019/03/03/链路监控/自己动手写一个简单的javaagent（总纲）/","link":"","permalink":"https://mayu1991.github.io/2019/03/03/链路监控/自己动手写一个简单的javaagent（总纲）/","excerpt":"需求 实现对当前容器系统参数（cpu，内存，网络）的收集，并将信息上传到服务端。 实现一个对代码无侵入的探针，只要应用程序启动了，就自行运转，无需应用程序进行改造。 实现agent的心跳检测。 实现根据采样率调节数据收集量。","text":"需求 实现对当前容器系统参数（cpu，内存，网络）的收集，并将信息上传到服务端。 实现一个对代码无侵入的探针，只要应用程序启动了，就自行运转，无需应用程序进行改造。 实现agent的心跳检测。 实现根据采样率调节数据收集量。 需求分析 怎么在代码无侵入的要求下运行监控程序？ 如果要做到无侵入，那么探针势必要与应用程序运行在一个进程里。如果探针单独部署，应用程序肯定是要做代码层面的改造与探针服务进行交互。 如何将探针的程序注入到应用程序里呢？利用 javaagent的Instrument。 怎么收集当前容器信息？ 用javaagent实现无侵入部署，在启动应用程序的同时，注入探针的代码，探针会启动一个定时器，由定时器来控制触发系统指标收集的任务。 同时再启动一个定时器，实现心跳机制。 为什么要做心跳？因为agent是单独部署在客户端的，服务端是开发者自己能够hold住的，客户端就有点鞭长莫及。所以需要用心跳来知晓agent的运行情况。 用什么方式上传到服务端？ 服务端数据结构怎么设计，用什么样的DB保存数据？ 如何实现采样率的动态调节？ 技术准备 利用instrument agent实现探针无侵入 Instrument “java.lang.instrument”包的具体实现，依赖于JVMTI。在Java SE 5 及其后续版本当中，开发者可以在一个普通 Java 程序（带有 main 函数的 Java 类）运行时，通过 - javaagent参数指定一个特定的jar文件来启动 Instrumentation的代理程序。 Instrumentation 的最大作用，就是类定义动态改变和操作。而且指令里也可以加上一些启动参数。 怎么获取启动参数？ JVMTI JVMTI全称 JVM Tool Interface，是 JVM 暴露出来的一些供用户扩展的接口集合。JVMTI 是基于事件驱动的，JVM 每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者扩展自己的逻辑。 JVMTIAgent 其实就是一个动态库，利用 JVMTI 暴露出来的一些接口来干一些我们想做、但是正常情况下又做不到的事情。 JVMTIAgent有三个回调函数，分别是： Agent_OnLoad，启动时加载。 Agent_OnAttach，运行时加载，这里还需要利用java的attach原理。 Agent_OnUnload，卸载时加载。 个人感觉这里应该用启动时加载，因为监控程序应该是7*24小时运行，必须与被监控应用相同的生命周期。如果是运行时加载，在什么样的节点启动监控也是很难定义。 利用Byte buddy实现了类的运行时动态加载和类的加强 启动流程 加载agent配置 加载agent插件 初始化agent服务管理 SPIJDK内置的一种服务提供发现机制 动态加载BootService接口的实现类 插件加载、匹配和拦截 agent插件体系 插件的加载 自定义的类加载器AgentClassLoader 注册 动态加载 插件的匹配 插件的拦截 指定需要拦截的类：在AgentBuilder.type处，这里可以指定需要拦截的类 指定需要拦截的方法：在builder.method处，这里可以指定需要拦截的方法 将需要拦截的类重新定义加载【ByteBuddy】 代码PluginFinder初始化方法：遍历所有pluginDefine，并获取classMatch，放到不同的map中 Agent要搞清楚以下几个问题 代理的类和执行main的类是一个classloader吗？是的，用的是一个类加载器 12DEFAULT_LOADER = new AgentClassLoader(PluginBootstrap.class.getClassLoader()); Instrumentation、ByteBubble、OpenTracing、Grpc 怎么知道拦截了哪些类 拦截了之后如何加强这些类 采样率是什么作用 性能和采集效率的一个综合指标，采集率高了对客户端的CPU压力自然会上升，但是采集的数据多了，对业务使用自然是更好的。 一定要引入这么多插件的jar 怎么兼容不同版本的插件 Grpc传输和http传输的区别 次要问题： PluginDefine和AbstractClassEnhancePluginDefine有什么区别？ 参考Instrumentation介绍class类简介SPI和ServiceLoader公用API的安全狂街-自定义注解生命周期openTracing文档用 Maven 管理项目文件周期的技巧深入理解Java ClassLoader及在 JavaAgent 中的应用基于Java Instrument的Agent实现JAVA SPI详解","categories":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/categories/链路监控/"}],"tags":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/tags/链路监控/"},{"name":"javaagent","slug":"javaagent","permalink":"https://mayu1991.github.io/tags/javaagent/"},{"name":"java","slug":"java","permalink":"https://mayu1991.github.io/tags/java/"}]},{"title":"分布式事务常见解决方案","slug":"分布式/事务/分布式事务常见解决方案","date":"2019-03-01T16:00:00.000Z","updated":"2019-07-10T08:33:19.363Z","comments":true,"path":"2019/03/02/分布式/事务/分布式事务常见解决方案/","link":"","permalink":"https://mayu1991.github.io/2019/03/02/分布式/事务/分布式事务常见解决方案/","excerpt":"FescarFescar: Fast &amp; Easy Commit And Rollback关于开源分布式事务中间件Fescar的提问FESCAR：阿里重磅开源分布式事务解决方案","text":"FescarFescar: Fast &amp; Easy Commit And Rollback关于开源分布式事务中间件Fescar的提问FESCAR：阿里重磅开源分布式事务解决方案 XA基于消息的最终一致TCCSaga","categories":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"JAVA","slug":"JAVA","permalink":"https://mayu1991.github.io/tags/JAVA/"},{"name":"RPC","slug":"RPC","permalink":"https://mayu1991.github.io/tags/RPC/"},{"name":"REST","slug":"REST","permalink":"https://mayu1991.github.io/tags/REST/"}]},{"title":"Elasticsearch运维的思考","slug":"elastic/Elasticsearch运维的思考","date":"2019-02-22T16:00:00.000Z","updated":"2019-03-19T08:11:32.599Z","comments":true,"path":"2019/02/23/elastic/Elasticsearch运维的思考/","link":"","permalink":"https://mayu1991.github.io/2019/02/23/elastic/Elasticsearch运维的思考/","excerpt":"当前的情况 当前每一个租户一共会创建95个索引。 分片的设置是：indexShardsNumber=2，indexReplicasNumber=0。 集群一共有四个节点，每一个节点有60G的空间。 目前线上共有6个租户，计算下来一共是1,140个分片","text":"当前的情况 当前每一个租户一共会创建95个索引。 分片的设置是：indexShardsNumber=2，indexReplicasNumber=0。 集群一共有四个节点，每一个节点有60G的空间。 目前线上共有6个租户，计算下来一共是1,140个分片 产生了哪些问题 副本数为0，没有备份，当主分区出现故障的时候，容错缺失。 分区数设置不合理，一般情况下分区数应该是节点数的1.5——3倍（因为es的分区数设置之后再调整很麻烦，所以评估好数据规模很重要），目前有4个节点，合理的分区数应该是6-18之间。 目前节点的容量以及数量很有可能跟不上业务的发展，如果大规模推广，存储机器的成本压力很大。 如何解决这些问题1. 预估集群大小索引吞吐量文档大小搜索吞吐量查询类型热点索引文档数量保留策略响应时间需求SLA 级别 2. 优化索引设计3. 扩大集群容量 数据迁移 步骤1：按照新需求，创建你需要分片的索引。 步骤2：reindex迁移 解决了这些问题之后，带来的变化问题解决之后的思考参考：Elasticsearch之如何合理分配索引分片Elasticsearch最佳实践之分片使用优化深入理解Shard和Lucene Indexebay的Elasticsearch调优实践","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/categories/elasticsearch/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/tags/elasticsearch/"},{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"运维","slug":"运维","permalink":"https://mayu1991.github.io/tags/运维/"}]},{"title":"RPC与REST理解","slug":"分布式/服务框架/RPC与REST","date":"2019-02-17T16:00:00.000Z","updated":"2019-07-10T08:33:17.210Z","comments":true,"path":"2019/02/18/分布式/服务框架/RPC与REST/","link":"","permalink":"https://mayu1991.github.io/2019/02/18/分布式/服务框架/RPC与REST/","excerpt":"什么是采样率，采样率有什么作用？","text":"什么是采样率，采样率有什么作用？ 基本概念Web Service简单地说, 也就是服务器如何向客户端提供服务. 常用的方法有: RPC 所谓的远程过程调用 (面向方法) SOA 所谓的面向服务的架构(面向消息) REST 所谓的 Representational state transfer (面向资源) RPCRPC是Remote Procedure Call的缩写，字面意思是远程过程调用。但是说白了就是从本地机器去执行服务器上的一个函数。所以说 RPC 指的是一类日常的操作，是个很宽泛的概念。 RPC的思想是把本地函数映射到API，也就是说一个API对应的是一个方法。比如本地有一个getAllUsers，远程也能通过某种约定的协议来调用这个getAllUsers。至于这个协议是Socket、是HTTP还是别的什么并不重要（gRPC就是基于Http2.0的RPC框架）。 RPC中的主体都是动作，是个动词。 RPC像调用本地方法一样调用远程方法，通信协议大多采用二进制方式 RESTREST是Representational State Transfer的缩写，翻译过来是表现层状态转换。如果一个架构符合REST原则，就称它为RESTful架构。 REST是一种架构风格，汲取了WWW的成功经验：无状态，以资源为中心，充分利用HTTP协议和URI协议，提供统一的接口定义，使得它作为一种设计Web服务的方法而变得流行。在某种意义上，通过强调URI和HTTP等早期Internet标准，REST是对大型应用程序服务器时代之前的Web方式的回归。 REST的主体都是资源，是名词。 REST通常是Http+json、Http+xml，常见的http api都可以称为Rest接口。 Q&amp;A 什么是资源呢？就是我们平常上网访问的一张图片、一个文档、一个视频等。这些资源我们通过URI来定位，也就是一个URI表示一个资源。 面向资源是什么意思？和面向动作比较优劣点在哪里？ 差异主体HTTP请求往往围绕资源，而RPC的请求往往围绕一个动作。 调用协议接口调用通常包含两个部分，序列化和通信协议。 常见的序列化协议包括Json、Xml、Hession、Protobuf、Thrift、Text、Bytes等； 通信比较流行的是HTTP、soap、websockect、TCP等。 通信协议 RPC通常基于TCP协议实现，常用框架例如gRpc，Netty、Mina、Thrift。 RESTful是基于HTTP协议实现。 RPC和RESTful的差别很大程度上是使用HTTP和TCP协议的区别。 序列化协议 HTTP通常使用Json。 RPC通常是使用RPC框架，这些RPC框架采用的序列化协议比如Protobuf、Thrift性能都高于Json或者XML。 几种序列化协议的比较 使用场景 Http相对更规范，更标准，更通用，无论哪种语言都支持Http协议。 RPC服务则需要客户端接口与服务端保持一致（会带来一些耦合），服务端提供一个方法，客户端通过接口直接发起调用，业务开发人员仅需要关注业务方法的调用即可，不再关注网络传输的细节，在开发上更为高效。 通常在公司内部接口调用会选择RPC，简单高效。对外开放的API通常选择REST，标准规范通用。 参考：Web Service实践之REST vs RPCHTTP 请求和 JSON-RPC序列化和反序列化HTTP协议入门TCP协议入门","categories":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"JAVA","slug":"JAVA","permalink":"https://mayu1991.github.io/tags/JAVA/"},{"name":"RPC","slug":"RPC","permalink":"https://mayu1991.github.io/tags/RPC/"},{"name":"REST","slug":"REST","permalink":"https://mayu1991.github.io/tags/REST/"}]},{"title":"如何避免过多的ifelse","slug":"java基础/如何避免过多的ifelse","date":"2018-11-09T16:00:00.000Z","updated":"2019-03-19T09:39:22.355Z","comments":true,"path":"2018/11/10/java基础/如何避免过多的ifelse/","link":"","permalink":"https://mayu1991.github.io/2018/11/10/java基础/如何避免过多的ifelse/","excerpt":"一般的if/else判断大多集中在以下三种情型 空值判断 业务判断 状态判断","text":"一般的if/else判断大多集中在以下三种情型 空值判断 业务判断 状态判断 处理方法 对控制判断的处理，可以把接口分为内接口和外接口，将空值判断都放在外接口，这样进入内接口的时候就不需要考虑空值判断。 利用多态，抽象出处理基类，对每一种业务类型，用专门的实现类来处理对应逻辑。 这里会带来一个问题，暴露给用户的类就多了，因为需要根据不同的业务场景创建不同的业务实现类，这时解决的方法： 再封装一层，将实现类的权限降低，只暴露给用户创建实现类的方法。 用工厂模式产生类。 用map将类型与类加载到map中，在使用时根据业务类型动态加载实现类。 参考减少该死的 if else 嵌套","categories":[{"name":"代码整洁","slug":"代码整洁","permalink":"https://mayu1991.github.io/categories/代码整洁/"}],"tags":[{"name":"代码整洁","slug":"代码整洁","permalink":"https://mayu1991.github.io/tags/代码整洁/"},{"name":"JAVA","slug":"JAVA","permalink":"https://mayu1991.github.io/tags/JAVA/"}]},{"title":"观察者模式与事件监听器","slug":"设计模式/观察者模式与事件监听器","date":"2018-10-16T16:00:00.000Z","updated":"2019-03-25T02:42:14.212Z","comments":true,"path":"2018/10/17/设计模式/观察者模式与事件监听器/","link":"","permalink":"https://mayu1991.github.io/2018/10/17/设计模式/观察者模式与事件监听器/","excerpt":"观察者模式和事件监听器的区别，以及各自的使用场景。","text":"观察者模式和事件监听器的区别，以及各自的使用场景。 观察者模式和发布-订阅模式参考 -&gt; 观察者模式 vs 发布-订阅模式 观察者模式和发布订阅模式最大的区别应该是，前者的Observer明确的知道Publisher，而后者，Publisher和Observer之间还有一个Coordinator，Publisher和Observer都不知道对方，只通过事件，由Coordinator实现消息的通信。 两者都有松耦合的功效，在一个应用之中，通常是使用观察者模式。在跨系统或跨服务的场景下，通常是使用发布订阅模式。 Java 9 的响应式编程 监听器模式监听器入门看这篇就够了 事件监听器和观察者模式的异同参考 -&gt; java设计模式-回调、事件监听器、观察者模式 发布订阅模式在dubbo的应用dubbo的订阅和注册怎么实现的Dubbo原理及其所涉及到的设计模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://mayu1991.github.io/categories/设计模式/"}],"tags":[{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"设计模式","slug":"设计模式","permalink":"https://mayu1991.github.io/tags/设计模式/"}]},{"title":"代理模式","slug":"设计模式/代理模式","date":"2018-10-12T16:00:00.000Z","updated":"2019-03-19T08:27:33.129Z","comments":true,"path":"2018/10/13/设计模式/代理模式/","link":"","permalink":"https://mayu1991.github.io/2018/10/13/设计模式/代理模式/","excerpt":"代理模式的优缺点优点 协调调用者和被调用者，降低了系统的耦合度 代理对象作为客户端和目标对象之间的中介，起到了保护目标对象的作用","text":"代理模式的优缺点优点 协调调用者和被调用者，降低了系统的耦合度 代理对象作为客户端和目标对象之间的中介，起到了保护目标对象的作用 缺点 由于在客户端和真实主题之间增加了代理对象，因此会造成请求的处理速度变慢； 实现代理模式需要额外的工作（有些代理模式的实现非常复杂），从而增加了系统实现的复杂度。 使用场景其实就是针对优点的一些使用场景： 因为安全原因需要屏蔽客户端直接访问对象。 在远程调用中需要使用代理类处理远程方法调用的技术细节 (如 RMI)。 为了提升系统性能，对真实对象进行封装，从而达到延迟加载的目的。 保护代理：控制目标对象的访问，给不同用户提供不同的访问权限 智能引用代理，额外操作包括耗时操作、计算访问次数等等。目的：在不影响对象类的情况下，在访问对象时进行更多的操作。 虚拟代理：通过使用过一个小的对象代理一个大对象。 远程代理：为一个对象在不同的地址空间提供局部代表。 防火墙代理：保护目标不让恶意用户靠近。 Cache代理：为结果提供临时的存储空间，以便其他客户端调用。 延迟加载在系统启动时，将消耗资源最多的方法都使用代理模式分离，可以加快系统的启动速度，减少用户的等待时间。而在用户真正做查询操作时再由代理类单独去加载真实的数据库查询类，完成用户的请求。这个过程就是使用代理模式实现了延迟加载。 如果当前并没有使用这个组件，则不需要真正地初始化它，使用一个代理对象替代它的原有的位置，只要在真正需要的时候才对它进行加载。 动态代理动态代理的本质是，在运行时动态生成代理类，这是相对于静态代理而言的。静态代理会定义一个代理类（如ClientProxy.java），通过这个代理类来调用真实类。而动态代理没有这个代理类，只需要定义一些生成规则，代理类会在运行时动态生成。 动态代理类使用字节码动态生成加载技术，代理类的字节码将在运行时生成并载入当前代理的ClassLoader。生成动态代理类的方法很多，如JDK自带的动态处理、CGLIB、Javassist或者ASM库。 JDK 的动态代理使用简单，它内置在 JDK 中，因此不需要引入第三方 Jar 包，但相对功能比较弱。 CGLIB 和 Javassist 都是高级的字节码生成库，总体性能比 JDK 自带的动态代理好，而且功能十分强大。 ASM 是低级的字节码生成工具，使用 ASM 已经近乎于在使用 Java bytecode 编程，对开发人员要求最高，当然，也是性能最好的一种动态代理生成工具。但 ASM 的使用很繁琐，而且性能也没有数量级的提升，与 CGLIB 等高级字节码生成工具相比，ASM 程序的维护性较差，如果不是在对性能有苛刻要求的场合，还是推荐 CGLIB 或者 Javassist。 动态代理的一般处理流程： 【生成代理类的字节码】根据指定的回调类生成动态代理类的字节码。 【生成代理类】将字节码装载到ClassLoader中，完成类的加载。 【生成代理类的实例】生成动态类的实例，并返回该实例。 jdk proxy Demo 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//被代理的接口public interface IDBQuery &#123; String request();&#125;//被代理接口的真实实现类@Slf4jpublic class DBQuery implements IDBQuery &#123; public DBQuery() &#123; try &#123; log.info(\"get db connection...begin\"); Thread.sleep(1000);//假设数据库连接等耗时操作 log.info(\"get db connection...end\"); &#125; catch (InterruptedException ex) &#123; log.error(ex.getLocalizedMessage()); &#125; &#125; @Override public String request() &#123; return \"request string\"; &#125;&#125;//负责代理类的生成@Slf4jpublic class DBQueryJDKHandler implements InvocationHandler &#123; IDBQuery realQuery = null;//定义主题接口 public DBQueryJDKHandler(IDBQuery query) &#123; this.realQuery = query; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; log.info(\"[DBQueryJDKHandler][invoke] method = \", method.getName()); return method.invoke(realQuery, args); &#125;&#125;//测试jdk proxy代理类@RunWith(SpringRunner.class)public class ProxyTest &#123; @Test public void testJdkProxy() &#123; IDBQuery idbProxy = (IDBQuery) Proxy.newProxyInstance( ClassLoader.getSystemClassLoader(), new Class[]&#123;IDBQuery.class&#125;, new DBQueryJDKHandler(new DBQuery())); idbProxy.request(); &#125;&#125; cglib proxy Demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//被代理的真实类@Slf4jpublic class Hello &#123; public void sayHello() &#123; log.info(&quot;[Hello][sayHello]...&quot;); &#125;&#125;//拦截真实类的方法以生成代理类@Slf4jpublic class HelloInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; log.info(&quot;[HelloInterceptor][intercept]...&quot;); return proxy.invokeSuper(obj, args); &#125;&#125;//封装了下cglib代理类的生成代码public class HelloFactory &#123; private static HelloFactory instance; static &#123; instance = new HelloFactory(); &#125; public static HelloFactory getInstance() &#123; return instance; &#125; public Hello create() &#123; Enhancer enhancer = new Enhancer(); //指定回调类 enhancer.setCallback(new HelloInterceptor()); //指定真实类 enhancer.setSuperclass(Hello.class); //生成代理类的实例 return (Hello) enhancer.create(); &#125;&#125;//测试代理类的生成@Testpublic void testCglibProxy() &#123; Hello hello = HelloFactory.getInstance().create(); hello.sayHello();&#125; jdk动态代理和cglib的比较 功能\\模块 jdk proxy cglib 指定回调类 实现InvocationHandler的自定义handler 拦截器，实现MethodInterceptor的自定义interceptor 类的装载 利用反射InvocationHandler.invoke() MethodInterceptor.intercept() 生成类的实例 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 反射 Enhancer enhancer = new Enhancer();enhancer.setSuperclass(真实类);enhancer.setCallback(回调处理类);enhancer.create(); 优点 实现比较简单，Java原生支持的，不需要任何外部依赖 通过继承的方式进行代理，无论目标对象有没有实现接口都可以代理 缺点 基于接口，如果对象没有实现接口就懵逼了 无法处理final的情况 效率 创建对象快 创建之后的对象运行快 总结下： jdkproxy生成的动态类是java.lang.reflect.Proxy的子类，所有的JDK动态代理都会继承这个类。 cglib生成的动态类是真实类的子类。所以就涉及到final的问题。 final类型不能有子类，所以CGLIB不能代理final类型。 final方法是不能重载的，所以也不能通过CGLIB代理，遇到这种情况不会抛异常，而是会跳过final方法只代理其他方法。 cglib做了方法访问优化，使用建立方法索引的方式避免了传统Method的方法反射调用。 Javassist一个开源的分析、编辑和创建 Java 字节码的类库。直接操作class文件，可以修改class文件内容。性能较ASM 差，跟cglib差不多，但是使用简单。很多开源框架都在使用它。 优势： 比反射开销小，性能高。 JAVAsist性能高于反射，低于ASM 怎么用可以参考：动态字节码操作-Javassist介绍Javassist 使用指南（一） ByteBuddyByte Buddy 是直接对字节码编程的框架。当然在速度上会优于javassist。 Byte Buddy 的主要侧重点在于以最少的运行时生成代码。通常，类型创建或操作不是任何程序中的常见步骤，并不会对任何长期运行的应用程序产生重大影响；特别是因为类加载或类构建（class instrumentation）是运行此类代码时最耗时且不可避免的步骤。 具体的效率可以参见下表（从网上扣的图，没有实测过） 思考 还有其他方式实现延迟加载吗？ 为什么jdk proxy要基于接口实现？ 这是一种设计思路。jdk是面向接口的代理。 对应JDK动态代理机制是委托机制，具体说动态实现接口类，在动态生成的实现类里面委托为hanlder去调用原始实现类方法。 比如接口类为Abo,实现类为AboImpl,AboImpl的代理类为ProxyAoImpl ，那么ProxyAoImpl 能赋值给Abo?能够赋值给AboImpl？ ProxyAoImpl 是能够赋值给Abo的，因为前者间接实现了后者，但是ProxyAoImpl 不能赋值给AboImpl因为他们没有继承或者实现关系。所以回顾下自己项目中Rpc里面autowired时候都是对bo类进行的，而不是对boimpl，并且我们的boimpl类一般都是配置了事务切面被代理过的。 对应Cglib则使用的继承机制，具体说被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的,如果被代理类有接口，那么代理类也可以赋值给接口。 jvm类加载的原理？ 拦截器的实现原理？ 监听器的实现原理？ Spring事务失效（事务嵌套），JDK动态代理给Spring事务埋下的坑？ 动态代理（CGLib 与 JDK）、优缺点、性能对比、如何选择？ 正向代理反向代理参考：代理模式原理及实例讲解代理模式（Proxy Pattern）- 最易懂的设计模式解析Java Proxy 和 CGLIB 动态代理原理Java反射机制及API使用CGLIB介绍与原理深入理解RPC之动态代理篇Java JDK代理、CGLIB、AspectJ代理分析比较深入分析Java方法反射的实现原理Byte Buddy 教程","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://mayu1991.github.io/categories/设计模式/"}],"tags":[{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"设计模式","slug":"设计模式","permalink":"https://mayu1991.github.io/tags/设计模式/"}]},{"title":"Elasticsearch的集群节点和分区","slug":"elastic/Elasticsearch的集群节点和分区","date":"2018-09-02T16:00:00.000Z","updated":"2019-03-19T08:26:36.335Z","comments":true,"path":"2018/09/03/elastic/Elasticsearch的集群节点和分区/","link":"","permalink":"https://mayu1991.github.io/2018/09/03/elastic/Elasticsearch的集群节点和分区/","excerpt":"在存储方面，elasticsearch可以看作一个分布式数据库。每一个节点可以看作是一个库，这些节点（分库）在集群内协同工作。一个索引可以看作是库里的表。","text":"在存储方面，elasticsearch可以看作一个分布式数据库。每一个节点可以看作是一个库，这些节点（分库）在集群内协同工作。一个索引可以看作是库里的表。 节点一个节点(node)就是一个Elasticsearch实例。 集群一个集群(cluster)由一个或多个节点组成，它们具有相同cluster.name，它们协同工作，分享数据和负载。当加入新的节点或者删除一个节点时，集群就会感知到并平衡数据。 集群中一个节点会被选举为主节点(master)，它将临时管理集群级别的一些变更，例如新建或删除索引、增加或移除节点等。主节点不参与文档级别的变更或搜索，这意味着在流量增长的时候，该主节点不会成为集群的瓶颈。任何节点都可以成为主节点。 做为用户，我们能够与集群中的任何节点通信，包括主节点。每一个节点都知道文档存在于哪个节点上，它们可以转发请求到相应的节点上。我们访问的节点负责收集各节点返回的数据，最后一起返回给客户端。这一切都由Elasticsearch处理。 主节点是否保存数据？ 因为节点之间存在负载均衡，所以我们访问的节点可以是集群中的任意一个节点，当我们请求一个节点时，我们需要的文档不一定在该节点上，此时该节点负责收集各节点返回的数据。如果是这样的原理，那么确实要求每一个节点都知道文档的存放位置。 索引添加索引为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”. 一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分 ^如何切分。我们的文档存储在分片中，并且在分片中被索引，但是我们的应用程序不会直接与它们通信，取而代之的是，直接与索引通信。","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/categories/elasticsearch/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/tags/elasticsearch/"},{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"},{"name":"索引","slug":"索引","permalink":"https://mayu1991.github.io/tags/索引/"}]},{"title":"Elasticsearch的分布式设计原理","slug":"elastic/Elasticsearch的分布式设计原理","date":"2018-08-31T16:00:00.000Z","updated":"2019-03-19T08:27:01.550Z","comments":true,"path":"2018/09/01/elastic/Elasticsearch的分布式设计原理/","link":"","permalink":"https://mayu1991.github.io/2018/09/01/elastic/Elasticsearch的分布式设计原理/","excerpt":"","text":"ElasticSearch 如何保证数据一致性,实时性为什么ES不适合做数据存储 Elastic主节点选举算法？？？","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/categories/elasticsearch/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://mayu1991.github.io/tags/elasticsearch/"},{"name":"todo","slug":"todo","permalink":"https://mayu1991.github.io/tags/todo/"}]},{"title":"Dapper的学习与思考","slug":"链路监控/Dapper的学习与思考","date":"2018-08-04T16:00:00.000Z","updated":"2019-03-19T08:26:12.496Z","comments":true,"path":"2018/08/05/链路监控/Dapper的学习与思考/","link":"","permalink":"https://mayu1991.github.io/2018/08/05/链路监控/Dapper的学习与思考/","excerpt":"链路监控的设计目标 低消耗 在低消耗层面，Dapper提出采样率这个概念，用采样率来调节Agent的资源消耗。 应用级的透明 无处不在的部署，应用级别的透明。 延展性","text":"链路监控的设计目标 低消耗 在低消耗层面，Dapper提出采样率这个概念，用采样率来调节Agent的资源消耗。 应用级的透明 无处不在的部署，应用级别的透明。 延展性 Q：采样率是什么？如何能够调节Agent的资源消耗。Q：如何实现代码的无侵入，或者极低的侵入？ Dapper的分布式跟踪跟踪树和调用链 跟踪树 调用链 调用链从字面上就很好理解，即一次完整的调用过程，可以看作是一条调用链路。一条调用链上会有很多的节点（span）。在分布式环境下，这些节点这些节点可能有很多差异。 跨技术架构，RPC、HTTP、MYSQL、MQ等等； 跨线程甚至跨主机，可能是在一个线程内，也可能是跨线程，甚至跨主机； 调用方式不同，可能是同步，也可能是异步。 跨语言，如JAVA、C、C++等 所以，我们可以推断出，如果要画出一个链路，需要在span（节点）中需要记录哪些数据： TraceId 链路ID，记录节点和链路的关系； spanId和spanName 节点的ID和NAME，标识本节点； parentId 父节点的ID，标识节点间的层级关系； times 节点消耗时间，这个我觉得是可选的。 Q：span的维度，即在什么情况下程序会创建一个新的span？Q：节点的通信，即本节点怎么将自己的ID传递给下一个span以做为下一个节点的parentId？A：见植入点章节 植入点 同一个线程内的span，用ThreadLocal进行存储。 延迟调用或者异步调用，通过线程池或者其他执行器，在回调里存储这次跟踪的上下文，在回调函数被触发的时候，这次跟踪的上下文会与适当的线程关联上。 跨语言，google的技术架构中进程间通信几乎都是C++或者Java开发的RPC框架，Dapper做为google自用的监控工具，把跟踪植入了google的RPC框架（估计是gRPC）里，非google的RPC框架估计目前还不支持。 Annotation 通过加一个注解，将某个方法强制加入到链路中去，猜测是跟采样率有关，强行生成一个span？ 用法 添加简单文本文本 像是自定义监控的功能。 比如：下单的方法createOrder()上加注解@Annotation(“createOrder”) 添加key-value健值对 这是官方文档的解释，Dapper也支持的key-value映射的 Annotation，提供给开发人员更强的跟踪能力，如持续的计数器，二进制消息记录和在一个进程上跑着的任意的用户数据。键值对的Annotation方式用来在分布式追踪的上下文中定义某个特定应用程序的相关类型。 @Annotation(“createOrder”,”1”) 为了避免滥用的风险，每一个跟踪span有一个可配置的总Annotation量的上限。 Q：Annotation注解有什么作用？A：估计要看Tracer.record这个方法做了什么事情…Q：Annotation注解有哪些应用场景？相当于是Dapper提供出来的API？注解应该只能加在方法上，不如直接调用Trace.record()方法来得方便，但是直接调用方法，会有滥用的风险。 采样率跟踪的收集 首先，span数据写入（1）本地日志文件中【Agent】。 然后Dapper的守护进程和收集组件把这些数据从生产环境的主机中拉出来（2）【Collector】。 最终写到（3）Dapper的Bigtable仓库中【Storage】。 监控数据可视化，Dapper提供API来访问Storage中的数据【Analysis &amp;&amp; UI】。 Q：日志文件打印在客户端，传输完之后即删除，还是日志文件到达一定大小的时候再删除？ 带外数据跟踪收集怎么理解带外数据（out-of-band）呢？out-of-band是通过其他的链路进行跟踪数据的收集，比如将span的跟踪数据写到日志里，由Daemon线程进行收集，这就是带外策略。与之相反的，in-band策略是把跟踪数据随着调用链传送下去。 为什么要采用带外数据收集呢？ 首先，如果采用带内收集方案，会影响应用程序网络动态。 如果采用带内方案，跟踪数据势必要以RPC响应头的形式被返回，通常RPC回应小于10K，但是在Google里的许多规模较大的系统中，一次跟踪成千上万的span并不少见，在这种调用链路非常深的情况下，带内收集方案产生的跟踪数据会造成比较大的网络传输负担，整个跟踪的时间也会变得特别长，失去了数据的实时性。 其次，带内收集方案假定所有的RPC是完美嵌套的。我们发现，在所有的后端的系统返回的最终结果之前，有许多中间件会把结果返回给他们的调用者。带内收集系统是无法解释这种非嵌套的分布式执行模式的。 安全和隐私考虑没看懂原文的这部分内容。 Dapper部署状况Dapper运行库对基础RPC、线程控制和流程控制的组件库的植入。包括span的创建，采样率的设置，以及把日志写入本地磁盘。 生产环境下的涵盖面 应用使用支持的组件库，支持无侵入开发的跟踪。 应用使用非标准的组件库，需要应该手动控制，或者将非标准的组件可以接入Dapper。 支持关闭Dapper跟踪。 跟踪Annotation的使用感觉是自定义监控，将业务代码加入到监控中。 处理跟踪损耗跟踪系统的成本由两部分组成： 正在被监控的系统在生成和收集追踪数据的消耗导致系统性能下降。 需要使用一部分资源来存储和分析跟踪数据。 生成跟踪的损耗生成跟踪的开销是Dapper性能影响中最关键的部分，因为收集和分析可以更容易在紧急情况下被关闭。 创建和销毁span和annotation 创建根span的消耗要大于其他span，原因是在创建根span的时候，需要生成整个链路的traceId。 记录到本地磁盘供后续的收集 写入磁盘是最大的消耗，可以通过异步写入减少对应用系统的影响。但是在大流量的情况下，这部分的消耗还是需要重视。 收集跟踪的损耗 CPU使用率 守护进程的单核cpu使用率很低，没超过0.3% 限制了Dapper守护进程为内核scheduler最低的优先级，防止发生CPU竞争 带宽资源 Dapper的数据收集在Google的生产环境中的只占用了0.01%的网络资源 在生产环境下对负载的影响 （延迟和吞吐的实验误差分别是2.5%和0.15%） 我们看到，虽然对吞吐量的影响不是很明显，但为了避免明显的延迟，跟踪的采样还是必要的。然而，延迟和吞吐量的带来的损失在把采样率调整到小于1/16之后就全部在实验误差范围内。在实践中，我们发现即便采样率调整到1/1024仍然是有足够量的跟踪数据的用来跟踪大量的服务。保持Dapper的性能损耗基线在一个非常低的水平是很重要的，因为它为那些应用提供了一个宽松的环境使用完整的Annotation API而无惧性能损失。使用较低的采样率还有额外的好处，可以让持久化到硬盘中的跟踪数据在垃圾回收机制处理之前保留更长的时间，这样为Dapper的收集组件给了更多的灵活性。 可变采样我们在部署可变采样的过程中，参数化配置采样率时，不是使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的追踪。这样一来，低流量低负载自动提高采样率，而在高流量高负载的情况下会降低采样率，使损耗一直保持在控制之下。实际使用的采样率会随着跟踪本身记录下来，这有利于从Dapper的跟踪数据中准确的分析。 Q：怎么实现这种可变采样的？A：我们充分利用所有span都来自一个特定的跟踪并分享同一个跟踪ID这个事实，虽然这些span有可能横跨了数千个主机。对于在收集系统中的每一个span，我们用hash算法把跟踪ID转成一个标量Z，这里0&lt;=Z&lt;=1。如果Z比我们收集系统中的系数低的话，我们就保留这个span信息，并写入到Bigtable中。反之，我们就抛弃他。通过在采样决策中的跟踪ID，我们要么保存、要么抛弃整个跟踪，而不是单独处理跟踪内的span。我们发现，有了这个额外的配置参数使管理我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整我们的全局写入率这个参数。 其他收获Dapper的不足： 合并的影响：我们的模型隐含的前提是不同的子系统在处理的都是来自同一个被跟踪的请求。在某些情况下，缓冲一部分请求，然后一次性操作一个请求集会更加有效。（比如，磁盘上的一次合并写入操作）。在这种情况下，一个被跟踪的请求可以看似是一个大型工作单元。此外，当有多个追踪请求被收集在一起，他们当中只有一个会用来生成那个唯一的跟踪ID，用来给其他span使用，所以就无法跟踪下去了。我们正在考虑的解决方案，希望在可以识别这种情况的前提下，用尽可能少的记录来解决这个问题。 跟踪批处理负载：Dapper的设计，主要是针对在线服务系统，最初的目标是了解一个用户请求产生的系统行为。然而离线的密集型负载例如符合MapReduce[10]模型的情况，也可以受益于性能挖潜。在这种情况下，我们需要把跟踪ID与一些其他的有意义的工作单元做关联，诸如输入数据中的键值（或键值的范围），或是一个MapReduce shard。 寻找根源-与业务数据结合不紧密：Dapper可以有效地确定系统中的哪一部分致使系统整个速度变慢，但并不总是能够找出问题的根源。例如，一个请求很慢有可能不是因为它自己的行为，而是由于队列中其他排在它前面的(queued ahead of)请求还没处理完。程序可以使用应用级的annotation把队列的大小或过载情况写入跟踪系统。此外，如果这种情况屡见不鲜，那么在ProfileMe[11]中提到的成对的采样技术可以解决这个问题。它由两个时间重叠的采样率组成，并观察它们在整个系统中的相对延迟。 记录内核级的信息：一些内核可见的事件的详细信息有时对确定问题根源是很有用的。我们有一些工具，能够跟踪或以其他方式描述内核的执行，但是，想用通用的或是不那么突兀的方式，是很难把这些信息到捆绑到用户级别的跟踪上下文中。我们正在研究一种妥协的解决方案，我们在用户层面上把一些内核级的活动参数做快照，然后绑定他们到一个活动的span上。 知识点 ThreadLocal 线程池 RPC框架 自定义注解 Bigtable MapReduce模型 采样率参考浅述APM采样与端到端 参考1. Dapper，大规模分布式系统的跟踪系统2. 全链路监控（一）：方案概述与比较","categories":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/categories/链路监控/"}],"tags":[{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/tags/链路监控/"}]},{"title":"采样率","slug":"链路监控/采样率","date":"2018-07-31T16:00:00.000Z","updated":"2019-03-19T08:26:00.240Z","comments":true,"path":"2018/08/01/链路监控/采样率/","link":"","permalink":"https://mayu1991.github.io/2018/08/01/链路监控/采样率/","excerpt":"采样最直接的目的有两个：减少计算量和降低描述难度。","text":"采样最直接的目的有两个：减少计算量和降低描述难度。 在APM厂商中，普遍采用这样一种采样算法来计算Apdex（Application Performance Index）。 Apdex的计算公式是： Apdex ＝ ( 1 x 满意 ＋0.5 x 容忍 ＋ 0 x 失望 ) / 样本数。 我们套一下上面的公式： 假定样本为：小于2s的请求次数为10次，满意； 大于2s，小于8s的请求次数为20次，容忍；大于等于8s的请求次数为10次，失望。 那么得到 Apdex = ( 1 x 10 + 0.5 x 20 + 0 x 10 ) / 40 = 0.5 ，结果是Unacceptable 不能接受的，说明这次采样的这个系统就在GG 的边缘了。 但是Apdex公式的计算只是在一个宏观上判断一个服务的综合状态，如果细化的话，这个计算公式是一个加权的结果，如果有5个请求都是大于等于8s,但是其他35个都是小于2s的，那么得出的Apdex为0.875，已经是Good的状态了，但是如果这8s的5个请求是服务的主入口或者重要接口，那么这Good的表面价值就会带来巨大隐患，所以对于采样率的计算，需要对于宏观上有一套计算方案，也需要对于细节处进行探查。 参考全链路分布式跟踪系统与APM浅述APM采样与端到端","categories":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://mayu1991.github.io/tags/分布式/"},{"name":"链路监控","slug":"链路监控","permalink":"https://mayu1991.github.io/tags/链路监控/"}]},{"title":"Linux常用指令","slug":"常用操作/linux/Linux常用指令-1","date":"2018-06-30T16:00:00.000Z","updated":"2019-03-19T08:09:33.852Z","comments":true,"path":"2018/07/01/常用操作/linux/Linux常用指令-1/","link":"","permalink":"https://mayu1991.github.io/2018/07/01/常用操作/linux/Linux常用指令-1/","excerpt":"给目录设置用户和用户组chown -R admin:admin admin/","text":"给目录设置用户和用户组chown -R admin:admin admin/ 删除用户userdel [用户名]删除某一个用户，eg：删除admin用户userdel admin 修改账户密码passwd [账户名] 修改某一个账户的密码，eg：修改admin的密码passwd admin passwd 修改root账户的密码 新增账户adduser [用户名] 创建用户密码和目录 useradd [用户名] 只创建用户，不创建目录 安装lsrzyum -y install lrzsz; 压缩和解压安装zip命令yum -y install unzip zip 解压到指定目录tar xvf filename.tar -C /specific dir ##给admin账号sudo权限vi /etc/sudoersadmin ALL=(ALL) ALL 修改别名vi ~/.bashrcsource ~/.bashrc 查看目录树下各个文件的大小du -m [文件目录]-m 表示以M为单位 查看监听端口netstat -tulpn | grep LISTEN 文件夹复制cp -r [source] [target]将source文件夹下的内容复制到target文件夹下。-r 遍历文件夹下所有目录 eg: 1cp -r /home/admin/kk-apm-web /home/admin/kk-apm/1.0.3/","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mayu1991.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://mayu1991.github.io/tags/Linux/"}]},{"title":"Mac下设置指令别名","slug":"常用操作/mac/Mac下增加指令别名-1","date":"2018-06-19T16:00:00.000Z","updated":"2019-03-19T08:11:48.871Z","comments":true,"path":"2018/06/20/常用操作/mac/Mac下增加指令别名-1/","link":"","permalink":"https://mayu1991.github.io/2018/06/20/常用操作/mac/Mac下增加指令别名-1/","excerpt":"指令alias [别名]=’[指令名称]’","text":"指令alias [别名]=’[指令名称]’ 临时有效（重启失效） 在命令行中输入别名指令，如：alias ll=&#39;ls -alh 取消的命令为：unalias ll 永久生效 在bash_profile文件中vim ~/.bash_profile加入别名指令，如： 等号两边均无空格，指令名称中如有空格，需用引号包裹 source ~/.bash_profile使其生效 也可以修改 /etc/profile文件，不过这个是全家配置脚本，修改了所有用户都会生效。 登录shell会话的启动文件 文件 内容 /etc/profile 应用于所有用户的全局配置脚本 ~/.bash_profile 用户私人的启动文件 ~/.bash_login 如果~/.bash_profile没有找到，会尝试读取这个文件 ~/.profile 如果~/.bash_profile和~/.bash_login没有找到，会尝试读取这个文件","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://mayu1991.github.io/categories/博客搭建/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://mayu1991.github.io/tags/博客搭建/"}]},{"title":"从零开始搭建个人博客","slug":"常用操作/博客搭建/从零搭建个人博客","date":"2018-06-09T16:00:00.000Z","updated":"2019-07-10T08:26:34.187Z","comments":true,"path":"2018/06/10/常用操作/博客搭建/从零搭建个人博客/","link":"","permalink":"https://mayu1991.github.io/2018/06/10/常用操作/博客搭建/从零搭建个人博客/","excerpt":"从零开始搭建一个个人博客系统记录。","text":"从零开始搭建一个个人博客系统记录。 准备git安装git，并将本地的公钥维护到github，这样可以免密提交代码【MAC上Git安装与GitHub基本使用】 在本机安装git 设置user.name和user.email配置信息，加global是全局变量，也可以在单个项目目录里单独设置局部变量，去掉global即可。 12git config --global user.name &quot;你的GitHub用户名&quot;git config --global user.email &quot;你的GitHub注册邮箱&quot; 生成本地ssh密钥文件，输入：ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot; 将本地生成的公钥维护到github里 测试是否成功，输入：ssh git@github.com，查看是否有返回。 安装node在mac上安装node.js 安装Hexo在本地创建文件夹，以存放hexo代码，以及博客文章。 进入博客文件夹下，使用npm命令安装Hexo，输入：npm install -g hexo-cli 安装完成后，初始化博客，输入：hexo init blog 部署网站，绑定github的repositories 在blog目录下，修改_config.yml文件。 type : git repo : github pages托管的资源库地址+”.git” branch : master 1234deploy: type: git repo: https://github.com/mayu1991/mayu1991.github.io.git branch: master 安装Git部署插件，在博客文件夹下，输入命令：npm install hexo-deployer-git --save，如果不执行这个命令，在hexo d的时候会报错。 Q&amp;A Mac下安装npm全局包提示权限不够 启动Hexo 清除缓存 hexo clean 启动服务预览 hexo s == hexo server 部署到git hexo d == hexo deploy 这一步是将本地hexo编译后的js推送github代码库，然后利用github pages实现博客在公网发布。 hexo指令列表 新建文章 hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; 清除缓存 hexo clean 生成hexo g == hexo generate 启动服务预览hexo s == hexo server 部署hexo d == hexo deploy 更换Hexo主题Hexo主题库 我用了melody这个主题主题作者的博客git地址 主题接入步骤 将主题下载到博客所在theme文件夹下 路径：/Users/mayu/Documents/blogs/blog/themes 指令：git clone -b master https://github.com/Molunerfinn/hexo-theme-melody 安装了一个插件 指令：npm install hexo-renderer-jade hexo-renderer-stylus 按照接入文档操作 调整博客设置 头像 标签 目录 相册 搜索 访问日志 字数统计 要为theme-melody配上字数统计特性, 你需要如下几个步骤: 打开hexo工作目录 npm install hexo-wordcount --save或者yarn add hexo-wordcount 配置melody.yml: 12wordcount: enable: true TODO 评论功能 集成 Baidu Analytics 和 Google Analytics 绑定域名 常用的工具 在线颜色选择器 iPic图床-图片上传 参考文章1. GitHub+Hexo 搭建个人网站详细教程2. 我的博客是如何搭建的（github pages + HEXO + 域名绑定）3. melody主题博客接入文档4. hexo教程5. 在mac上安装node.js","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://mayu1991.github.io/categories/博客搭建/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://mayu1991.github.io/tags/博客搭建/"}]}]}